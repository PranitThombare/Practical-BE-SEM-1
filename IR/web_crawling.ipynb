{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve https://www.amazon.in/s?k=products&page=1 with status code: 503\n",
      "Failed to retrieve https://www.amazon.in/s?k=products&page=2 with status code: 503\n",
      "Failed to retrieve https://www.amazon.in/s?k=products&page=3 with status code: 503\n",
      "Failed to retrieve https://www.amazon.in/s?k=products&page=4 with status code: 503\n",
      "Failed to retrieve https://www.amazon.in/s?k=products&page=5 with status code: 503\n"
     ]
    }
   ],
   "source": [
    "# web_crawler.py\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "class EcommerceCrawler:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.products = []\n",
    "\n",
    "    def fetch_page(self, url):\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"Failed to retrieve {url} with status code: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    def parse_product_page(self, html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        product_elements = soup.select('.s-main-slot .s-result-item')  # Example selector for Amazon\n",
    "        for product in product_elements:\n",
    "            title = product.select_one('h2 .a-link-normal').text.strip() if product.select_one('h2 .a-link-normal') else 'N/A'\n",
    "            price = product.select_one('.a-price .a-offscreen').text.strip() if product.select_one('.a-price .a-offscreen') else 'N/A'\n",
    "            link = product.select_one('h2 .a-link-normal')['href'] if product.select_one('h2 .a-link-normal') else 'N/A'\n",
    "            self.products.append({\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'link': self.base_url + link  # Ensure the link is absolute\n",
    "            })\n",
    "\n",
    "    def crawl(self, start_page, num_pages):\n",
    "        for page in range(start_page, start_page + num_pages):\n",
    "            url = f\"{self.base_url}/s?k=products&page={page}\"  # Adjust URL pattern as needed\n",
    "            html = self.fetch_page(url)\n",
    "            if html:\n",
    "                self.parse_product_page(html)\n",
    "            # Introduce a delay between requests\n",
    "            time.sleep(random.uniform(2, 5))  # Random delay between 2 to 5 seconds\n",
    "\n",
    "    def display_products(self):\n",
    "        for product in self.products:\n",
    "            print(f\"Title: {product['title']}, Price: {product['price']}, Link: {product['link']}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://www.flipkart.in\"  # Replace with the actual e-commerce site\n",
    "    crawler = EcommerceCrawler(base_url)\n",
    "    crawler.crawl(start_page=1, num_pages=5)  # Adjust the number of pages to crawl\n",
    "    crawler.display_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
